{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LIWC: Linguistic Inquiry and Word Count  analyzer\n",
    "\n",
    "\n",
    "\n",
    "https://cliwc.weebly.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Language left behind on social media exposes the emotional and cognitive costs of a romantic breakup**\n",
    "\n",
    "Sarah Seraj,  Kate G. Blackburn, and James W. Pennebaker\n",
    "\n",
    "PNAS February 16, 2021 118 (7) e2017154118; https://doi.org/10.1073/pnas.2017154118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Abstract\n",
    "\n",
    "Using archived social media data, the language signatures of people going through breakups were mapped. Text analyses were conducted on 1,027,541 posts from 6,803 Reddit users who had posted about their breakups. The posts include users’ Reddit history in the 2 y surrounding their breakups across the various domains of their life, not just posts pertaining to their relationship. Language markers of an impending breakup were evident 3 mo before the event, peaking on the week of the breakup and returning to baseline 6 mo later. Signs included an increase in I-words, we-words, and cognitive processing words (characteristic of depression, collective focus, and the meaning-making process, respectively) and drops in analytic thinking (indicating more personal and informal language). The patterns held even when people were posting to groups unrelated to breakups and other relationship topics. People who posted about their breakup for longer time periods were less well-adjusted a year after their breakup compared to short-term posters. The language patterns seen for breakups replicated for users going through divorce (n = 5,144; 1,109,867 posts) or other types of upheavals (n = 51,357; 11,081,882 posts). The cognitive underpinnings of emotional upheavals are discussed using language as a lens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "日常生活中的情感分析\n",
    "\n",
    "- 忧郁与自杀者往往在语言与文字之中发出可侦测的求救信号，但是我们能否有效的敏感到这些信息？（Chung & Pennebaker，2007）\n",
    "-  初次约会对象之间几分钟的对话可以预测彼此的好感？情侣间的对话可以预测几个月之后持续交往的机率？（Ireland & Pennebaker，2010）\n",
    "-  团体的凝聚力和合作倾向在对话之中就能够被侦测？（Gonzales，Hancock，& Pennebaker，2010）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "日常生活中的情感分析\n",
    "\n",
    "- 你的男/女朋友欺骗你吗？谎言侦测的研究，可以告诉你说谎的语言特性，让你分辨真假之间。（Newman，Pennebaker，Berry，& Richards，2003）\n",
    "- 还用老套的占星术认识新朋友？最潮的语言分析可以助你一臂之力。（Pennebaker & King，1999）\n",
    "- 岁月的印记不只在容颜，语言也可以揭开年龄的秘密。（Pennebaker & Stone，2003）\n",
    "\n",
    "\n",
    "LIWC词库已经开发了不同的语言版本。英文 版LIWC目前包含了64个词语类别，例如，常用的语词类别(代名词、冠词、应和词、 停顿词等)，以及心理特征类别词汇(情感词汇、认知词汇)等。该词典将情感词汇分为积极情感词汇和消极情感词汇。其中，消极情感词汇包括焦虑、愤怒和伤心。\n",
    "https://liwc.wpengine.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The liwc Python Package\n",
    "\n",
    "https://github.com/chbrown/liwc-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:51:38.854988Z",
     "start_time": "2021-05-17T10:51:35.764890Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: liwc in /opt/anaconda3/lib/python3.7/site-packages (0.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/chbrown/liwc-python\n",
    "pip install liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T07:53:09.814266Z",
     "start_time": "2021-05-22T07:53:09.378820Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import liwc\n",
    "liwcPath = '/Users/datalab/OneDrive - nju.edu.cn/research/liwc/LIWC2007_English100131.dic'\n",
    "parse, category_names = liwc.load_token_parser(liwcPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- parse is a function from a token of text (a string) to a list of matching LIWC categories (a list of strings)\n",
    "- category_names is all LIWC categories in the lexicon (a list of strings)\n",
    "\n",
    "https://www.liwc.net/LIWC2007LanguageManual.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T07:53:17.540259Z",
     "start_time": "2021-05-22T07:53:17.537130Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affect posemo\n"
     ]
    }
   ],
   "source": [
    "print(*parse('happy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T07:53:26.324301Z",
     "start_time": "2021-05-22T07:53:26.315560Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funct pronoun ppron i we you shehe they ipron article verb auxverb past present future adverb preps conj negate quant number swear social family friend humans affect posemo negemo anx anger sad cogmech insight cause discrep tentat certain inhib incl excl percept see hear feel bio body health sexual ingest relativ motion space time work achieve leisure home money relig death assent nonfl filler\n"
     ]
    }
   ],
   "source": [
    "print(*category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image.png](img/liwc1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image.png](img/liwc2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image.png](img/liwc3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The LIWC lexicon only matches lowercase strings, so you will most likely want to lowercase your input text before passing it to parse(...). In the example above, I call .lower() on the entire string, but you could alternatively incorporate that into your tokenization process (e.g., by using spaCy's token.lower_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T07:55:48.831497Z",
     "start_time": "2021-05-22T07:55:48.827639Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    # you may want to use a smarter tokenizer\n",
    "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "        yield match.group(0)\n",
    "\n",
    "gettysburg = '''Four score and seven years ago our fathers brought forth on\n",
    "  this continent a new nation, conceived in liberty, and dedicated to the\n",
    "  proposition that all men are created equal. Now we are engaged in a great\n",
    "  civil war, testing whether that nation, or any nation so conceived and so\n",
    "  dedicated, can long endure. We are met on a great battlefield of that war.\n",
    "  We have come to dedicate a portion of that field, as a final resting place\n",
    "  for those who here gave their lives that that nation might live. It is\n",
    "  altogether fitting and proper that we should do this.'''.lower()\n",
    "gettysburg_tokens = tokenize(gettysburg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T07:55:52.049688Z",
     "start_time": "2021-05-22T07:55:52.045195Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'funct': 58, 'pronoun': 18, 'cogmech': 17, 'relativ': 17, 'verb': 13, 'ipron': 12, 'social': 11, 'preps': 10, 'conj': 9, 'incl': 9, 'space': 9, 'auxverb': 9, 'affect': 8, 'present': 8, 'time': 6, 'ppron': 6, 'article': 6, 'we': 5, 'posemo': 5, 'quant': 4, 'adverb': 4, 'past': 3, 'negemo': 3, 'anger': 3, 'tentat': 3, 'number': 2, 'motion': 2, 'certain': 2, 'death': 2, 'excl': 2, 'future': 2, 'family': 1, 'humans': 1, 'cause': 1, 'achieve': 1, 'work': 1, 'leisure': 1, 'they': 1, 'discrep': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "gettysburg_counts = Counter(category for token in gettysburg_tokens for category in parse(token))\n",
    "print(gettysburg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:50:04.788081Z",
     "start_time": "2021-05-17T10:50:04.776879Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "four score and seven years ago our fathers brought forth on this continent a new nation conceived in liberty and dedicated to the proposition that all men are created equal now we are engaged in a great civil war testing whether that nation or any nation so conceived and so dedicated can long endure we are met on a great battlefield of that war we have come to dedicate a portion of that field as a final resting place for those who here gave their lives that that nation might live it is altogether fitting and proper that we should do this\n"
     ]
    }
   ],
   "source": [
    "gettysburg_tokens = tokenize(gettysburg)\n",
    "print(*gettysburg_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T10:57:37.999520Z",
     "start_time": "2021-05-17T10:57:37.997374Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# liwcPath = '/Users/datalab/bigdata/LIWC2007_100131.dic'\n",
    "# parse, category_names = liwc.load_token_parser(liwcPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "like\t(02 134)125/464\t(02 134)126\t253\t466\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Another Package with the same name**\n",
    "\n",
    "https://github.com/evanll/liwc-text-analysis-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> pip install liwc-text-analysis\n",
    "\n",
    "    from liwc import Liwc\n",
    "\n",
    "    liwc = Liwc(LIWC_FILEPATH)\n",
    "\n",
    "Search a word in the dictionary to find in which LIWC categories it belongs\n",
    "\n",
    "    print(liwc.search('happy'))\n",
    "\n",
    "['affect', 'posemo']\n",
    "\n",
    "Extract raw counts of words in a document that fall into the various LIWC categories\n",
    "\n",
    "    print(liwc.parse('I love ice cream.'.split(' ')))\n",
    "\n",
    "Counter({'verb': 1, 'present': 1, 'affect': 1, 'posemo': 1, 'bio': 1, 'sexual': 1, 'social': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CLIWC\n",
    "中文版的LIWC詞典（簡稱C-LIWC）也在Pennebaker教授的授權下，於2012建立並正式發表（黃金蘭等人2012）\n",
    "https://cliwc.weebly.com/\n",
    "\n",
    "### 文心\n",
    "“文心(TextMind)”中文心理分析系统是由中科院心理所计算网络心理实验室研发的，针对中文文本进行语言分析的软件系统，通过“文心”，您可以便捷地分析文本中使用的不同类别语言的程度、偏好等特点。针对中国大陆地区简体环境下的语言特点，参照LIWC2007和正體中文C-LIWC词库，我们开发了“文心（TextMind）”中文心理分析系统。“文心”为用户提供从简体中文自动分词，到语言心理分析的一揽子分析解决方案，其词库、文字和符号等处理方法专门针对简体中文语境，词库分类体系也与LIWC兼容一致。\n",
    "http://ccpl.psych.ac.cn/textmind/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### liwc-analysis: Driver for LIWC2015 analysis.\n",
    "\n",
    "https://pypi.org/project/liwc-analysis/\n",
    "    \n",
    "https://github.com/EricWiener/liwc-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T03:48:24.122649Z",
     "start_time": "2021-05-18T03:48:17.665270Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting liwc-analysis\n",
      "  Downloading liwc_analysis-1.2.4-py2.py3-none-any.whl (5.5 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (from liwc-analysis) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->liwc-analysis) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->liwc-analysis) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->liwc-analysis) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->liwc-analysis) (1.12.0)\n",
      "Installing collected packages: liwc-analysis\n",
      "Successfully installed liwc-analysis-1.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install liwc-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T06:50:10.893732Z",
     "start_time": "2021-05-18T06:50:10.871574Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# load file and save contents to text variable\n",
    "rows = []\n",
    "LIWCLocation = '/Users/datalab/OneDrive - nju.edu.cn/research/liwc/LIWC2007_100131.dic'\n",
    "with open(LIWCLocation) as fp:\n",
    "    for line in fp:\n",
    "        rows.append(line)\n",
    "\n",
    "grid = [row.strip().replace('\\ufeff', '').split(\"\\t\") for row in rows if len(row) > 1]\n",
    "grid = [i for i in grid if len(i) > 1]\n",
    "num2cat = {i:j   for i,j in grid[:66]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T06:50:16.779042Z",
     "start_time": "2021-05-18T06:50:16.775438Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num2cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T07:01:08.577264Z",
     "start_time": "2021-05-18T07:01:08.559743Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dat = []\n",
    "for i in grid[66:]:\n",
    "    word, nums = i[0], i[1:]\n",
    "    for j in nums:\n",
    "        if j in num2cat:\n",
    "            dat.append((word,num2cat[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T07:01:35.797587Z",
     "start_time": "2021-05-18T07:01:35.774007Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "with open('/Users/datalab/OneDrive - nju.edu.cn/research/liwc/LIWC2007_all_word_category_pair.txt', 'w') as f:\n",
    "    for (word, category) in dat:\n",
    "        f.write(\"{} ,{}\\n\".format(word, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:00:28.403050Z",
     "start_time": "2021-05-22T08:00:27.934648Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import liwcanalysis\n",
    "\n",
    "LIWCLocation = '/Users/datalab/OneDrive - nju.edu.cn/research/liwc/Simplified_Chinese_LIWC2015_word_category_pair.txt'\n",
    "LIWC = liwcanalysis.liwc(LIWCLocation)\n",
    "result_dics, coutn_dics = LIWC.analyze(\"我 今天 很 伤心 。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:01:37.559612Z",
     "start_time": "2021-05-22T08:01:37.514652Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import liwcanalysis\n",
    "\n",
    "LIWCLocation = '/Users/datalab/OneDrive - nju.edu.cn/research/liwc/LIWC2007_all_word_category_pair.txt'\n",
    "LIWC = liwcanalysis.liwc(LIWCLocation)\n",
    "result_dics2, coutn_dics2 = LIWC.analyze(\"我 今天 很 开心 。\")\n",
    "result_dics3, coutn_dics3 = LIWC.analyze(\"I am very happy .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:01:40.332854Z",
     "start_time": "2021-05-22T08:01:40.328379Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb (Adverbs) 1\n",
      "focuspresent (Present Focus) 1\n",
      "function (Function Words) 3\n",
      "i (I) 1\n",
      "ppron (Personal Pronouns) 1\n",
      "pronoun (Pronouns) 1\n",
      "relativ (Relativity) 1\n",
      "tensem 1\n",
      "time (Time) 1\n"
     ]
    }
   ],
   "source": [
    "for i,j in coutn_dics[0].items():\n",
    "    if j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:01:56.431314Z",
     "start_time": "2021-05-22T08:01:56.426664Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb 1\n",
      "funct 3\n",
      "i 1\n",
      "ppron 1\n",
      "pronoun 1\n",
      "relativ 1\n",
      "time 1\n"
     ]
    }
   ],
   "source": [
    "for i,j in coutn_dics2[0].items():\n",
    "    if j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:00.657452Z",
     "start_time": "2021-05-22T08:02:00.652408Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb 1\n",
      "affect 1\n",
      "auxverb 1\n",
      "funct 2\n",
      "higharousal 2\n",
      "posemo 2\n",
      "present 1\n",
      "verb 1\n"
     ]
    }
   ],
   "source": [
    "for i,j in coutn_dics3[0].items():\n",
    "    if j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:05.018646Z",
     "start_time": "2021-05-22T08:02:05.013458Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb (Adverbs) ['很']\n",
      "focuspresent (Present Focus) ['今天']\n",
      "function (Function Words) ['我', '今天', '很']\n",
      "i (I) ['我']\n",
      "ppron (Personal Pronouns) ['我']\n",
      "pronoun (Pronouns) ['我']\n",
      "relativ (Relativity) ['今天']\n",
      "tensem ['今天']\n",
      "time (Time) ['今天']\n"
     ]
    }
   ],
   "source": [
    "for i,j in result_dics[0].items():\n",
    "    if j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:09.778590Z",
     "start_time": "2021-05-22T08:02:09.773882Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb ['很']\n",
      "funct ['我', '今天', '很']\n",
      "i ['我']\n",
      "ppron ['我']\n",
      "pronoun ['我']\n",
      "relativ ['今天']\n",
      "time ['今天']\n"
     ]
    }
   ],
   "source": [
    "for i,j in result_dics2[0].items():\n",
    "    if j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:11.975564Z",
     "start_time": "2021-05-22T08:02:11.970521Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb ['very']\n",
      "affect ['happy']\n",
      "auxverb ['am']\n",
      "funct ['am', 'very']\n",
      "higharousal ['happy', 'happy']\n",
      "posemo ['happy', 'happy']\n",
      "present ['am']\n",
      "verb ['am']\n"
     ]
    }
   ],
   "source": [
    "for i,j in result_dics3[0].items():\n",
    "    if j:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chinese LIWC Lexicon\n",
    "\n",
    "https://github.com/thunlp/Auto_CLIWC/blob/master/datasets/sc_liwc.dic\n",
    "    \n",
    "Auto LIWC\n",
    "\n",
    "Xiangkai Zeng, Cheng Yang, Cunchao Tu, Zhiyuan Liu, Maosong Sun. **Chinese LIWC Lexicon Expansion via Hierarchical Classification of Word Embeddings with Sememe Attention**. The 32nd AAAI Conference on Artificial Intelligence (AAAI 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:36.241995Z",
     "start_time": "2021-05-22T08:02:36.235562Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open('./data/sc_liwc.dic', 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:39.336857Z",
     "start_time": "2021-05-22T08:02:39.330082Z"
    },
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/thunlp/Auto_CLIWC/blob/master/utils/load_data.py\n",
    "def load_liwc(filename, encoding='utf-8'):\n",
    "    import io\n",
    "    liwc_file = io.open(filename, 'r', encoding=encoding)\n",
    "    lines = liwc_file.readlines()\n",
    "    type2name = dict()\n",
    "    word2type = dict()\n",
    "    type2word = dict()\n",
    "    lc = 0\n",
    "    for i, line in enumerate(lines):  # read type\n",
    "        if '%' in line:\n",
    "            lc = i\n",
    "            break\n",
    "        tmp = line.strip().split()\n",
    "        type2name[int(tmp[0])] = tmp[1]\n",
    "    for line in lines[lc + 1:]:\n",
    "        tmp = line.strip().split()\n",
    "        #if tmp[0] not in word2vec:\n",
    "            #continue\n",
    "        word2type[tmp[0]] = list(map(int, tmp[1:]))\n",
    "        for t in word2type[tmp[0]]:\n",
    "            type2word[t] = type2word.get(t, [])\n",
    "            type2word[t].append(tmp[0])\n",
    "    return type2name, word2type, type2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T08:02:41.911959Z",
     "start_time": "2021-05-22T08:02:41.890763Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "type2name, word2type, type2word = load_liwc('./data/sc_liwc.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T05:00:41.322091Z",
     "start_time": "2021-05-18T05:00:41.317996Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(type2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T08:23:13.848914Z",
     "start_time": "2021-05-18T08:23:13.843117Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'achieve (Achievement)': [],\n",
       "  'adverb (Adverbs)': ['很'],\n",
       "  'affect (Affect)': [],\n",
       "  'affiliation (Affiliation)': [],\n",
       "  'anger (Anger)': [],\n",
       "  'anx (Anx)': [],\n",
       "  'assent (Assent)': [],\n",
       "  'auxverb (Auxiliary Verbs)': [],\n",
       "  'bio (Biological Processes)': [],\n",
       "  'body (Body)': [],\n",
       "  'cause (Causal)': [],\n",
       "  'certain (Certainty)': [],\n",
       "  'cogproc (Cognitive Processes)': [],\n",
       "  'compare (Comparisons)': [],\n",
       "  'conj (Conjunctions)': [],\n",
       "  'death (Death)': [],\n",
       "  'differ (Differentiation)': [],\n",
       "  'discrep (Discrepancies)': [],\n",
       "  'drives (Drives)': [],\n",
       "  'family (Family)': [],\n",
       "  'feel (Feel)': [],\n",
       "  'female (Female)': [],\n",
       "  'filler (Filler Words)': [],\n",
       "  'focusfuture (Future Focus)': [],\n",
       "  'focuspast (Past Focus)': [],\n",
       "  'focuspresent (Present Focus)': ['今天'],\n",
       "  'friend (Friends)': [],\n",
       "  'function (Function Words)': ['我', '今天', '很'],\n",
       "  'general_pa': [],\n",
       "  'health (Health)': [],\n",
       "  'hear (Hear)': [],\n",
       "  'home (Home)': [],\n",
       "  'i (I)': ['我'],\n",
       "  'informal (Informal Language)': [],\n",
       "  'ingest (Ingest)': [],\n",
       "  'insight (Insight)': [],\n",
       "  'interrog (Interrogatives)': [],\n",
       "  'ipron (Impersonal Pronouns)': [],\n",
       "  'leisure (Leisure)': [],\n",
       "  'male (Male)': [],\n",
       "  'modal_pa': [],\n",
       "  'money (Money)': [],\n",
       "  'motion (Motion)': [],\n",
       "  'negate (Negations)': [],\n",
       "  'negemo (Negative Emotions)': [],\n",
       "  'netspeak (Netspeak)': [],\n",
       "  'nonflu (Nonfluencies)': [],\n",
       "  'number (Numbers)': [],\n",
       "  'particle': [],\n",
       "  'percept (Perceptual Processes)': [],\n",
       "  'posemo (Positive Emotions)': [],\n",
       "  'power (Power)': [],\n",
       "  'ppron (Personal Pronouns)': ['我'],\n",
       "  'prep (Prepositions)': [],\n",
       "  'prepend': [],\n",
       "  'progm': [],\n",
       "  'pronoun (Pronouns)': ['我'],\n",
       "  'quant (Quantifiers)': [],\n",
       "  'quanunit': [],\n",
       "  'relativ (Relativity)': ['今天'],\n",
       "  'relig (Religion)': [],\n",
       "  'reward (Reward)': [],\n",
       "  'risk (Risk)': [],\n",
       "  'sad (Sad)': [],\n",
       "  'see (See)': [],\n",
       "  'sexual (Sexual)': [],\n",
       "  'shehe (SheHe)': [],\n",
       "  'social (Social)': [],\n",
       "  'space (Space)': [],\n",
       "  'specart': [],\n",
       "  'swear (Swear)': [],\n",
       "  'tensem': ['今天'],\n",
       "  'tentat (Tentative)': [],\n",
       "  'they (They)': [],\n",
       "  'time (Time)': ['今天'],\n",
       "  'we (We)': [],\n",
       "  'work (Work)': [],\n",
       "  'you (You)': [],\n",
       "  'youpl': []}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "|                |                           |               |               |                            |      |      |\n",
    "| -------------- | ------------------------- | ------------- | ------------- | -------------------------- | ---- | ---- |\n",
    "| |LIWC DIMENSION | OUTPUT LABEL              | LIWC2015 MEAN | LIWC2007 MEAN | LIWC 2015/2007 CORRELATION |      |      |\n",
    "|                | Word Count                | WC            | 11,921.82     | 11,852.99                  | 1.00 |      |\n",
    "|                | **Summary Variable**      |               |               |                            |      |      |\n",
    "|                | Analytical Thinking       | Analytic      | 56.34         |                            |      |      |\n",
    "|                | Clout                     | Clout         | 57.95         |                            |      |      |\n",
    "|                | Authentic                 | Authentic     | 49.17         |                            |      |      |\n",
    "|                | Emotional Tone            | Tone          | 54.22         |                            |      |      |\n",
    "|                | **Language Metrics**      |               |               |                            |      |      |\n",
    "|                | Words per sentence1       | WPS           | 17.40         | 25.07                      | 0.74 |      |\n",
    "|                | Words>6 letters           | Sixltr        | 15.60         | 15.89                      | 0.98 |      |\n",
    "|                | Dictionary words          | Dic           | 85.18         | 83.95                      | 0.94 |      |\n",
    "|                | **Function Words**        | function      | 51.87         | 54.29                      | 0.95 |      |\n",
    "|                | Total pronouns            | pronoun       | 15.22         | 14.99                      | 0.99 |      |\n",
    "|                | Personal pronouns         | ppron         | 9.95          | 9.83                       | 0.99 |      |\n",
    "|                | 1st pers singular         | i             | 4.99          | 4.97                       | 1.00 |      |\n",
    "|                | 1st pers plural           | we            | 0.72          | 0.72                       | 1.00 |      |\n",
    "|                | 2nd person                | you           | 1.70          | 1.61                       | 0.98 |      |\n",
    "|                | 3rd pers singular         | shehe         | 1.88          | 1.87                       | 1.00 |      |\n",
    "|                | 3rd pers plural           | they          | 0.66          | 0.66                       | 0.99 |      |\n",
    "|                | Impersonal pronouns       | ipron         | 5.26          | 5.17                       | 0.99 |      |\n",
    "|                | Articles                  | article       | 6.51          | 6.53                       | 0.99 |      |\n",
    "|                | Prepositions              | prep          | 12.93         | 12.59                      | 0.96 |      |\n",
    "|                | Auxiliary verbs           | auxverb       | 8.53          | 8.82                       | 0.96 |      |\n",
    "|                | Common adverbs            | adverb        | 5.27          | 4.83                       | 0.97 |      |\n",
    "|                | Conjunctions              | conj          | 5.90          | 5.87                       | 0.99 |      |\n",
    "|                | Negations                 | negate        | 1.66          | 1.72                       | 0.96 |      |\n",
    "|                | **Grammar Other**         |               |               |                            |      |      |\n",
    "|                | Regular verbs             | verb          | 16.44         | 15.26                      | 0.72 |      |\n",
    "|                | Adjectives                | adj           | 4.49          |                            |      |      |\n",
    "|                | Comparatives              | compare       | 2.23          |                            |      |      |\n",
    "|                | Interrogatives            | interrog      | 1.61          |                            |      |      |\n",
    "|                | Numbers                   | number        | 2.12          | 1.98                       | 0.98 |      |\n",
    "|                | Quantifiers               | quant         | 2.02          | 2.48                       | 0.88 |      |\n",
    "|                | **Affect Words**          | affect        | 5.57          | 5.63                       | 0.96 |      |\n",
    "|                | Positive emotion          | posemo        | 3.67          | 3.75                       | 0.96 |      |\n",
    "|                | Negative emotion          | negemo        | 1.84          | 1.83                       | 0.96 |      |\n",
    "|                | Anxiety                   | anx           | 0.31          | 0.33                       | 0.94 |      |\n",
    "|                | Anger                     | anger         | 0.54          | 0.60                       | 0.97 |      |\n",
    "|                | Sadness                   | sad           | 0.41          | 0.39                       | 0.92 |      |\n",
    "|                | **Social Words**          | social        | 9.74          | 9.36                       | 0.96 |      |\n",
    "|                | Family                    | family        | 0.44          | 0.38                       | 0.94 |      |\n",
    "|                | Friends                   | friend        | 0.36          | 0.23                       | 0.78 |      |\n",
    "|                | Female referents          | female        | 0.98          |                            |      |      |\n",
    "|                | Male referents            | male          | 1.65          |                            |      |      |\n",
    "|                | **Cognitive Processes2**  | cogproc       | 10.61         | 14.99                      | 0.84 |      |\n",
    "|                | Insight                   | insight       | 2.16          | 2.13                       | 0.98 |      |\n",
    "|                | Cause                     | cause         | 1.40          | 1.41                       | 0.97 |      |\n",
    "|                | Discrepancies             | discrep       | 1.44          | 1.45                       | 0.99 |      |\n",
    "|                | Tentativeness             | tentat        | 2.52          | 2.42                       | 0.98 |      |\n",
    "|                | Certainty                 | certain       | 1.35          | 1.27                       | 0.92 |      |\n",
    "|                | Differentiation3          | differ        | 2.99          | 2.48                       | 0.85 |      |\n",
    "|                | **Perpetual Processes**   | percept       | 2.70          | 2.36                       | 0.92 |      |\n",
    "|                | Seeing                    | see           | 1.08          | 0.87                       | 0.88 |      |\n",
    "|                | Hearing                   | hear          | 0.83          | 0.73                       | 0.94 |      |\n",
    "|                | Feeling                   | feel          | 0.64          | 0.62                       | 0.92 |      |\n",
    "|                | **Biological Processes**  | bio           | 2.03          | 1.88                       | 0.94 |      |\n",
    "|                | Body                      | body          | 0.69          | 0.68                       | 0.96 |      |\n",
    "|                | Health/illness            | health        | 0.59          | 0.53                       | 0.87 |      |\n",
    "|                | Sexuality                 | sexual        | 0.13          | 0.28                       | 0.76 |      |\n",
    "|                | Ingesting                 | ingest        | 0.57          | 0.46                       | 0.94 |      |\n",
    "|                | **Core Drives and Needs** | drives        | 6.93          |                            |      |      |\n",
    "|                | Affiliation               | affiliation   | 2.05          |                            |      |      |\n",
    "|                | Achievement               | achieve       | 1.30          | 1.56                       | 0.93 |      |\n",
    "|                | Power                     | power         | 2.35          |                            |      |      |\n",
    "|                | Reward focus              | reward        | 1.46          |                            |      |      |\n",
    "|                | Risk/prevention focus     | risk          | 0.47          |                            |      |      |\n",
    "|                | **Time Orientation4**     |               |               |                            |      |      |\n",
    "|                | Past focus                | focuspast     | 4.64          | 4.14                       | 0.97 |      |\n",
    "|                | Present focus             | focuspresent  | 9.96          | 8.10                       | 0.92 |      |\n",
    "|                | Future focus              | focusfuture   | 1.42          | 1.00                       | 0.63 |      |\n",
    "|                | **Relativity**            | relativ       | 14.26         | 13.87                      | 0.98 |      |\n",
    "|                | Motion                    | motion        | 2.15          | 2.06                       | 0.93 |      |\n",
    "|                | Space                     | space         | 6.89          | 6.17                       | 0.96 |      |\n",
    "|                | Time                      | time          | 5.46          | 5.79                       | 0.94 |      |\n",
    "|                | **Personal Concerns**     |               |               |                            |      |      |\n",
    "|                | Work                      | work          | 2.56          | 2.27                       | 0.97 |      |\n",
    "|                | Leisure                   | leisure       | 1.35          | 1.37                       | 0.95 |      |\n",
    "|                | Home                      | home          | 0.55          | 0.56                       | 0.99 |      |\n",
    "|                | Money                     | money         | 0.68          | 0.70                       | 0.97 |      |\n",
    "|                | Religion                  | relig         | 0.28          | 0.32                       | 0.96 |      |\n",
    "|                | Death                     | death         | 0.16          | 0.16                       | 0.96 |      |\n",
    "|                | **Informal Speech**       | informal      | 2.52          |                            |      |      |\n",
    "|                | Swear words               | swear         | 0.21          | 0.17                       | 0.89 |      |\n",
    "|                | Netspeak                  | netspeak      | 0.97          |                            |      |      |\n",
    "|                | Assent                    | assent        | 0.95          | 1.11                       | 0.68 |      |\n",
    "|                | Nonfluencies              | nonfl         | 0.54          | 0.30                       | 0.84 |      |\n",
    "|                | Fillers                   | filler        | 0.11          | 0.40                       | 0.29 |      |\n",
    "|                | **All Punctuation5**      | Allpunc       | 20.47         | 22.90                      | 0.96 |      |\n",
    "|                | Periods                   | Period        | 7.46          | 7.91                       | 0.98 |      |\n",
    "|                | Commas                    | Comma         | 4.73          | 4.81                       | 0.98 |      |\n",
    "|                | Colons                    | Colon         | 0.63          | 0.63                       | 1.00 |      |\n",
    "|                | Semicolons                | SemiC         | 0.30          | 0.24                       | 0.98 |      |\n",
    "|                | Question marks            | QMark         | 0.58          | 0.95                       | 1.00 |      |\n",
    "|                | Exclamation marks         | Exclam        | 1.0           | 0.91                       | 1.00 |      |\n",
    "|                | Dashes                    | Dash          | 1.19          | 1.38                       | 0.98 |      |\n",
    "|                | Quotation marks           | Quote         | 1.19          | 1.38                       | 0.76 |      |\n",
    "|                | Apostrophes               | Apostro       | 2.13          | 2.83                       | 0.76 |      |\n",
    "|                | Parentheses (pairs)       | Parenth       | 0.52          | 0.25                       | 0.90 |      |\n",
    "|                | Other punctuation         | OtherP        | 0.72          | 1.38                       | 0.98 |      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "- Pennebaker, J. W. (1997). Writing about emotional experiences as a therapeutic process. Psychological Science, 8, 162-166.\n",
    "- Pennebaker, J.W., & Francis, M.E. (1996). Cognitive, emotional, and language processes in disclosure. Cognition and Emotion, 10, 601-626.\n",
    "- Pennebaker, J.W., & King, L.A. (1999). Linguistic styles: Language use as an individual difference. Journal of Personality and Social Psychology, 77, 1296-1312.\n",
    "- Pennebaker, J. W., Mayne, T., & Francis, M. E. (1997). Linguistic predictors of adaptive bereavement. Journal of Personality and Social Psychology, 72, 863-871.\n",
    "- Pennebaker, J.W. (2002). What our words can say about us: Toward a broader language psychology. Psychological Science Agenda, 15, 8-9.\n",
    "- Newman, M.L., Pennebaker, J.W., Berry, D.S., & Richards, J.M. (2003). Lying words: Predicting deception from linguistic styles. Personality and social psychology bulletin, 29, 5, 665-675."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
